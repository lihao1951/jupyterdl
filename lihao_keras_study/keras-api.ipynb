{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras学习\n",
    "## keras 函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数式编程与keras.Sequential 相比而言，更加灵活\n",
    "深度学习模型通常是一个DAG的层次模型，函数式API是其构建层次图的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minst数据\n",
    "# 输入数据 是784维的一维向量 ,批次大小通常需要忽略，因为需要根据实际的数据集大小来划分\n",
    "inputs = keras.Input(shape=(784,))\n",
    "# 也可以输入为一个32*32*3的tensor张量\n",
    "# img_inputs = keras.Input(shape=(32,32,3))\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 创建隐含层\n",
    "dense = layers.Dense(64,activation='relu')\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs,outputs=outputs,name='mnist_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "# \n",
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(10000,784).astype(\"float32\")/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 2s 44us/sample - loss: 0.3533 - accuracy: 0.8986 - val_loss: 0.1916 - val_accuracy: 0.9436\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 1s 22us/sample - loss: 0.1593 - accuracy: 0.9529 - val_loss: 0.1380 - val_accuracy: 0.9602\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=64,epochs=2,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0932 - accuracy: 0.9618\n",
      "Test loss:0.12943649917393923\n",
      "Test accuracy:0.9618\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(x_test,y_test,verbose=2)\n",
    "print('Test loss:%s' % test_scores[0])\n",
    "print('Test accuracy:%s' % test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\applications\\anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: mnist_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# 保存模型和加载模型\n",
    "model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0932 - accuracy: 0.9618\n",
      "Test loss:0.12943649917393923\n",
      "Test accuracy:0.9618\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = keras.models.load_model('mnist_model')\n",
    "test_scores = model.evaluate(x_test,y_test,verbose=2)\n",
    "print('Test loss:%s' % test_scores[0])\n",
    "print('Test accuracy:%s' % test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用相同的图定义多个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28,28,1),name='img')\n",
    "# Conv2D(filters,kernel_size) filters:是指的featuremap的层数，kernel_size指的是卷积核的大小比如 3*3，默认步长为（1，1），padding方式默认为valid\n",
    "x=layers.Conv2D(16,3,activation='relu')(encoder_input)\n",
    "x=layers.Conv2D(32,3,activation='relu')(x)\n",
    "# 最大池化层 MaxPooling2D(pool_size,strides):pool_size 可以是tuple 或者是integer，代表池化层的大小，默认strides为None，即和pool_size相同，padding方式默认为valid\n",
    "x=layers.MaxPooling2D(3)(x)\n",
    "x=layers.Conv2D(32,3,activation='relu')(x)\n",
    "x=layers.Conv2D(16,3,activation='relu')(x)\n",
    "# GlobalMaxPooling2D() 全局池化，池化层的大小为整个feature-map的大小，最终得到一个1*1*feature-map个数的张量\n",
    "encoder_output=layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input,encoder_output,name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autodecoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=layers.Reshape((4,4,1))(encoder_output)\n",
    "# 反卷积 将数据扩充，卷积的输入输出，在这里可看作反卷积的 输出 输入\n",
    "x=layers.Conv2DTranspose(16,3,activation='relu')(x)\n",
    "x=layers.Conv2DTranspose(32,3,activation='relu')(x)\n",
    "# 上采样\n",
    "x=layers.UpSampling2D(3)(x)\n",
    "x=layers.Conv2DTranspose(16,3,activation='relu')(x)\n",
    "decoder_output=layers.Conv2DTranspose(1,3,activation='relu')(x)\n",
    "autodecoder = keras.Model(encoder_input,decoder_output,name='autodecoder')\n",
    "autodecoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好模型后 ，你可以像使用layer一样使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建复杂的图拓扑\n",
    "### 定义有多个输入和输出的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multimodel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 64)     640000      title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 128)          98816       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tags (InputLayer)               [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 172)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 tags[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            173         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            692         concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,392,097\n",
      "Trainable params: 1,392,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_tags=12\n",
    "num_words=10000\n",
    "num_departments=4\n",
    "title_input=keras.Input(shape=(None,),name='title')\n",
    "body_input=keras.Input(shape=(None,),name='body')\n",
    "tags_input=keras.Input(shape=(num_tags,),name='tags')\n",
    "# embedding\n",
    "title_features=layers.Embedding(num_words,64)(title_input)\n",
    "body_features=layers.Embedding(num_words,64)(body_input)\n",
    "title_features=layers.LSTM(128)(title_features)\n",
    "body_features=layers.LSTM(32)(body_features)\n",
    "x=layers.concatenate([title_features,body_features,tags_input])\n",
    "priority_pred=layers.Dense(1,name='priority')(x)\n",
    "department_pred=layers.Dense(num_departments,name='department')(x)\n",
    "model=keras.Model(inputs=[title_input,body_input,tags_input],outputs=[priority_pred,department_pred],name='multimodel')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model,'multi_input_and_output_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights=[1.0, 0.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1280 samples\n",
      "Epoch 1/2\n",
      "1280/1280 [==============================] - 4s 3ms/sample - loss: 1.3079 - priority_loss: 0.7019 - department_loss: 3.0302\n",
      "Epoch 2/2\n",
      "1280/1280 [==============================] - 1s 1ms/sample - loss: 1.2995 - priority_loss: 0.6997 - department_loss: 2.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22fee879348>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建一个简单的ResNet网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cifar10_resnet\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 30, 30, 32)   896         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 28, 28, 64)   18496       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 9, 9, 64)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 9, 9, 64)     36928       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 9, 9, 64)     0           conv2d_7[0][0]                   \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 9, 9, 64)     36928       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 9, 9, 64)     36928       conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 9, 9, 64)     0           conv2d_9[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 7, 7, 64)     36928       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 64)           0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          16640       global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           2570        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 223,242\n",
      "Trainable params: 223,242\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(32,32,3),name='img')\n",
    "# 第一块block\n",
    "x=layers.Conv2D(32,3,activation='relu')(inputs)\n",
    "x=layers.Conv2D(64,3,activation='relu')(x)\n",
    "block_1_output=layers.MaxPooling2D(3)(x)\n",
    "# 第二块block\n",
    "x=layers.Conv2D(64,3,activation='relu',padding='same')(block_1_output)\n",
    "x=layers.Conv2D(64,3,activation='relu',padding='same')(x)\n",
    "block_2_output=layers.add([x,block_1_output])\n",
    "# 第三块block\n",
    "x=layers.Conv2D(64,3,activation='relu',padding='same')(block_2_output)\n",
    "x=layers.Conv2D(64,3,activation='relu',padding='same')(x)\n",
    "block_3_output=layers.add([x,block_2_output])\n",
    "# 输出\n",
    "x=layers.Conv2D(64,3,activation='relu')(block_3_output)\n",
    "x=layers.GlobalAveragePooling2D()(x)\n",
    "x=layers.Dense(256,activation='relu')(x)\n",
    "x=layers.Dropout(0.5)(x)\n",
    "outputs=layers.Dense(10)(x)\n",
    "\n",
    "model=keras.Model(inputs,outputs,name='cifar10_resnet')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train.astype(\"float\")/255.0\n",
    "x_test = x_test.astype(\"float\")/255.0\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 3s 3ms/sample - loss: 2.0966 - acc: 0.2887 - val_loss: 1.7715 - val_acc: 0.3450\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.7425 - acc: 0.3363 - val_loss: 1.8373 - val_acc: 0.3400\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6943 - acc: 0.3562 - val_loss: 1.7937 - val_acc: 0.3700\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.7168 - acc: 0.3613 - val_loss: 1.8567 - val_acc: 0.3300\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6735 - acc: 0.3613 - val_loss: 1.6235 - val_acc: 0.3650\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6991 - acc: 0.3700 - val_loss: 1.8516 - val_acc: 0.3250\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.5828 - acc: 0.4025 - val_loss: 1.6171 - val_acc: 0.3850\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6647 - acc: 0.3750 - val_loss: 1.6748 - val_acc: 0.3600\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6003 - acc: 0.3700 - val_loss: 1.8856 - val_acc: 0.3350\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6094 - acc: 0.4100 - val_loss: 1.5321 - val_acc: 0.4100\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.5593 - acc: 0.4062 - val_loss: 1.8519 - val_acc: 0.2650\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.6007 - acc: 0.4125 - val_loss: 1.7603 - val_acc: 0.3350\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.5599 - acc: 0.4013 - val_loss: 1.6872 - val_acc: 0.3750\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4906 - acc: 0.4425 - val_loss: 1.6806 - val_acc: 0.3450\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.5035 - acc: 0.4150 - val_loss: 1.7223 - val_acc: 0.3200\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.5072 - acc: 0.4300 - val_loss: 1.7674 - val_acc: 0.3600\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4830 - acc: 0.4313 - val_loss: 1.5637 - val_acc: 0.4100\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4463 - acc: 0.4425 - val_loss: 1.6663 - val_acc: 0.3350\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4610 - acc: 0.4613 - val_loss: 1.5297 - val_acc: 0.4000\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4126 - acc: 0.4825 - val_loss: 1.7318 - val_acc: 0.3250\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.3635 - acc: 0.4925 - val_loss: 1.6523 - val_acc: 0.3700\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4096 - acc: 0.4487 - val_loss: 1.5806 - val_acc: 0.3800\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.3538 - acc: 0.5038 - val_loss: 1.8177 - val_acc: 0.3850\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.3574 - acc: 0.4975 - val_loss: 2.0127 - val_acc: 0.3500\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.4673 - acc: 0.4900 - val_loss: 1.5028 - val_acc: 0.4000\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2284 - acc: 0.5462 - val_loss: 1.6372 - val_acc: 0.3800\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2737 - acc: 0.5275 - val_loss: 1.7045 - val_acc: 0.3050\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2205 - acc: 0.5375 - val_loss: 1.6547 - val_acc: 0.3950\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1878 - acc: 0.5600 - val_loss: 2.3490 - val_acc: 0.3100\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2593 - acc: 0.5375 - val_loss: 1.8748 - val_acc: 0.4050\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1867 - acc: 0.5600 - val_loss: 1.8394 - val_acc: 0.3400\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2080 - acc: 0.5487 - val_loss: 1.8852 - val_acc: 0.3900\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1130 - acc: 0.5825 - val_loss: 1.8080 - val_acc: 0.4150\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.2017 - acc: 0.5550 - val_loss: 1.9403 - val_acc: 0.3450\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.0643 - acc: 0.5975 - val_loss: 1.6270 - val_acc: 0.4200\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1067 - acc: 0.5950 - val_loss: 2.2201 - val_acc: 0.3000\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1262 - acc: 0.5763 - val_loss: 1.8041 - val_acc: 0.3650\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.0704 - acc: 0.5950 - val_loss: 2.3734 - val_acc: 0.3100\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1381 - acc: 0.6000 - val_loss: 2.3490 - val_acc: 0.2850\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.1474 - acc: 0.5913 - val_loss: 1.6859 - val_acc: 0.4000\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9273 - acc: 0.6600 - val_loss: 1.9137 - val_acc: 0.3650\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.0393 - acc: 0.6263 - val_loss: 1.7274 - val_acc: 0.4050\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9727 - acc: 0.6325 - val_loss: 2.5962 - val_acc: 0.3300\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.0087 - acc: 0.6313 - val_loss: 1.6217 - val_acc: 0.4450\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9944 - acc: 0.6263 - val_loss: 1.6996 - val_acc: 0.4300\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9563 - acc: 0.6425 - val_loss: 1.6147 - val_acc: 0.4400\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 1.0664 - acc: 0.6225 - val_loss: 1.6829 - val_acc: 0.4250\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7118 - acc: 0.7613 - val_loss: 3.0204 - val_acc: 0.3150\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9493 - acc: 0.6587 - val_loss: 1.9646 - val_acc: 0.3400\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.8984 - acc: 0.6675 - val_loss: 2.2184 - val_acc: 0.3850\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7729 - acc: 0.7113 - val_loss: 2.2899 - val_acc: 0.4000\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9651 - acc: 0.6600 - val_loss: 2.0025 - val_acc: 0.3800\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7978 - acc: 0.7063 - val_loss: 1.7219 - val_acc: 0.4250\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7545 - acc: 0.7350 - val_loss: 1.7538 - val_acc: 0.4700\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9123 - acc: 0.6875 - val_loss: 2.0472 - val_acc: 0.4250\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6403 - acc: 0.7775 - val_loss: 2.4095 - val_acc: 0.3950\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7531 - acc: 0.7400 - val_loss: 2.5412 - val_acc: 0.4200\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7993 - acc: 0.7250 - val_loss: 2.1297 - val_acc: 0.4500\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6904 - acc: 0.7588 - val_loss: 1.8790 - val_acc: 0.4150\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9274 - acc: 0.7050 - val_loss: 1.9863 - val_acc: 0.4550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7467 - acc: 0.7462 - val_loss: 1.8789 - val_acc: 0.4550\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.8130 - acc: 0.7287 - val_loss: 2.2586 - val_acc: 0.4150\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.5522 - acc: 0.8100 - val_loss: 2.0771 - val_acc: 0.4450\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.5910 - acc: 0.7837 - val_loss: 2.1771 - val_acc: 0.4300\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.8369 - acc: 0.7462 - val_loss: 2.1043 - val_acc: 0.4200\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.4968 - acc: 0.8288 - val_loss: 3.0058 - val_acc: 0.4050\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7219 - acc: 0.7763 - val_loss: 2.2942 - val_acc: 0.4600\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6393 - acc: 0.7962 - val_loss: 1.9344 - val_acc: 0.4700\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7472 - acc: 0.7563 - val_loss: 2.5892 - val_acc: 0.3900\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6132 - acc: 0.8037 - val_loss: 2.2556 - val_acc: 0.4850\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6808 - acc: 0.7738 - val_loss: 2.1298 - val_acc: 0.4500\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.3700 - acc: 0.8712 - val_loss: 2.7886 - val_acc: 0.3650\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6297 - acc: 0.7887 - val_loss: 2.6099 - val_acc: 0.4750\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.4728 - acc: 0.8275 - val_loss: 4.0810 - val_acc: 0.3550\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7034 - acc: 0.7875 - val_loss: 2.3951 - val_acc: 0.4200\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6425 - acc: 0.7900 - val_loss: 2.1252 - val_acc: 0.4550\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6499 - acc: 0.8025 - val_loss: 2.1703 - val_acc: 0.4650\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.2927 - acc: 0.9025 - val_loss: 2.6604 - val_acc: 0.4200\n",
      "Epoch 79/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.5284 - acc: 0.8112 - val_loss: 3.2762 - val_acc: 0.4300\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6703 - acc: 0.7775 - val_loss: 2.7061 - val_acc: 0.4100\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.3199 - acc: 0.8925 - val_loss: 2.5752 - val_acc: 0.4550\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7128 - acc: 0.7887 - val_loss: 2.3271 - val_acc: 0.4350\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.2839 - acc: 0.8988 - val_loss: 2.8945 - val_acc: 0.4500\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.4668 - acc: 0.8612 - val_loss: 2.6066 - val_acc: 0.4250\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.9069 - acc: 0.7925 - val_loss: 2.4805 - val_acc: 0.4100\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.2464 - acc: 0.9350 - val_loss: 2.7690 - val_acc: 0.4550\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.1825 - acc: 0.9450 - val_loss: 4.7531 - val_acc: 0.3700\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7101 - acc: 0.8125 - val_loss: 2.7797 - val_acc: 0.4650\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.2017 - acc: 0.9438 - val_loss: 4.1035 - val_acc: 0.4100\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.7860 - acc: 0.7962 - val_loss: 2.4762 - val_acc: 0.5050\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.2201 - acc: 0.9388 - val_loss: 4.3565 - val_acc: 0.3700\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.8730 - acc: 0.7912 - val_loss: 2.4849 - val_acc: 0.4800\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.1162 - acc: 0.9725 - val_loss: 3.2299 - val_acc: 0.4400\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6718 - acc: 0.8525 - val_loss: 3.9566 - val_acc: 0.4000\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.4180 - acc: 0.8988 - val_loss: 2.6364 - val_acc: 0.4650\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.1231 - acc: 0.9650 - val_loss: 3.2427 - val_acc: 0.4400\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.6878 - acc: 0.8475 - val_loss: 2.6245 - val_acc: 0.4650\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.3810 - acc: 0.8975 - val_loss: 4.3740 - val_acc: 0.3400\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.3863 - acc: 0.8888 - val_loss: 2.6689 - val_acc: 0.4950\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 2s 2ms/sample - loss: 0.4894 - acc: 0.8913 - val_loss: 4.1358 - val_acc: 0.3450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22f817b3048>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3),loss=keras.losses.CategoricalCrossentropy(from_logits=True),metrics=['acc'])\n",
    "model.fit(x_train[:1000],y_train[:1000],batch_size=64,epochs=100,validation_split=0.2,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共享层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, None, 100])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shared_embedding = keras.layers.Embedding(1000,100)\n",
    "text_input_a = keras.layers.Input(shape=(None,),dtype=\"int32\")\n",
    "text_input_b = keras.layers.Input(shape=(None,),dtype=\"int32\")\n",
    "shared_a = shared_embedding(text_input_a)\n",
    "shared_b = shared_embedding(text_input_b)\n",
    "shared_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 制定自己的layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "继承Layer类，并且实现call和build方法\n",
    "call方法是最终layer输出的结果\n",
    "build方法用来创建权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "custom_dense_3 (CustomDense) (None, 10)                50        \n",
      "=================================================================\n",
      "Total params: 50\n",
      "Trainable params: 50\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CustomDense(layers.Layer):\n",
    "    def __init__(self,units=32):\n",
    "        super(CustomDense,self).__init__()\n",
    "        self.units = units\n",
    "    def build(self,input_shape):\n",
    "        self.w = self.add_weight(shape=(input_shape[-1],self.units),initializer='random_normal',trainable=True)\n",
    "        self.b = self.add_weight(shape=(self.units,),initializer='random_normal',trainable=True)        \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs,self.w) + self.b\n",
    "inputs = keras.Input((4,))\n",
    "outputs = CustomDense(10)(inputs)\n",
    "model = keras.Model(inputs,outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
