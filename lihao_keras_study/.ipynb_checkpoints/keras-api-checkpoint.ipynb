{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras学习\n",
    "## keras 函数式API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数式编程与keras.Sequential 相比而言，更加灵活\n",
    "深度学习模型通常是一个DAG的层次模型，函数式API是其构建层次图的工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minst数据\n",
    "# 输入数据 是784维的一维向量 ,批次大小通常需要忽略，因为需要根据实际的数据集大小来划分\n",
    "inputs = keras.Input(shape=(784,))\n",
    "# 也可以输入为一个32*32*3的tensor张量\n",
    "# img_inputs = keras.Input(shape=(32,32,3))\n",
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 784])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建隐含层\n",
    "dense = layers.Dense(64,activation='relu')\n",
    "x = dense(inputs)\n",
    "x = layers.Dense(64,activation='relu')(x)\n",
    "outputs = layers.Dense(10)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mnist_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                50240     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 55,050\n",
      "Trainable params: 55,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Model(inputs=inputs,outputs=outputs,name='mnist_model')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始训练\n",
    "# \n",
    "(x_train,y_train),(x_test,y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784).astype(\"float32\")/255\n",
    "x_test = x_test.reshape(10000,784).astype(\"float32\")/255\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 2s 35us/sample - loss: 0.3548 - accuracy: 0.8986 - val_loss: 0.1831 - val_accuracy: 0.9506\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 1s 29us/sample - loss: 0.1572 - accuracy: 0.9534 - val_loss: 0.1394 - val_accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,batch_size=64,epochs=2,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0751 - accuracy: 0.9592\n",
      "Test loss:0.1352165571048856\n",
      "Test accuracy:0.9592\n"
     ]
    }
   ],
   "source": [
    "test_scores = model.evaluate(x_test,y_test,verbose=2)\n",
    "print('Test loss:%s' % test_scores[0])\n",
    "print('Test accuracy:%s' % test_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mnist_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# 保存模型和加载模型\n",
    "model.save('mnist_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 0s - loss: 0.0751 - accuracy: 0.9592\n",
      "Test loss:0.1352165571048856\n",
      "Test accuracy:0.9592\n"
     ]
    }
   ],
   "source": [
    "del model\n",
    "model = keras.models.load_model('mnist_model')\n",
    "test_scores = model.evaluate(x_test,y_test,verbose=2)\n",
    "print('Test loss:%s' % test_scores[0])\n",
    "print('Test accuracy:%s' % test_scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用相同的图定义多个模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 18,672\n",
      "Trainable params: 18,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28,28,1),name='img')\n",
    "# Conv2D(filters,kernel_size) filters:是指的featuremap的层数，kernel_size指的是卷积核的大小比如 3*3，默认步长为（1，1），padding方式默认为valid\n",
    "x=layers.Conv2D(16,3,activation='relu')(encoder_input)\n",
    "x=layers.Conv2D(32,3,activation='relu')(x)\n",
    "# 最大池化层 MaxPooling2D(pool_size,strides):pool_size 可以是tuple 或者是integer，代表池化层的大小，默认strides为None，即和pool_size相同，padding方式默认为valid\n",
    "x=layers.MaxPooling2D(3)(x)\n",
    "x=layers.Conv2D(32,3,activation='relu')(x)\n",
    "x=layers.Conv2D(16,3,activation='relu')(x)\n",
    "# GlobalMaxPooling2D() 全局池化，池化层的大小为整个feature-map的大小，最终得到一个1*1*feature-map个数的张量\n",
    "encoder_output=layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input,encoder_output,name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autodecoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 32)          9248      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 16)          4624      \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 6, 6, 16)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 8, 8, 32)          4640      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 26, 26, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 28, 28, 1)         145       \n",
      "=================================================================\n",
      "Total params: 28,241\n",
      "Trainable params: 28,241\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x=layers.Reshape((4,4,1))(encoder_output)\n",
    "# 反卷积 将数据扩充，卷积的输入输出，在这里可看作反卷积的 输出 输入\n",
    "x=layers.Conv2DTranspose(16,3,activation='relu')(x)\n",
    "x=layers.Conv2DTranspose(32,3,activation='relu')(x)\n",
    "# 上采样\n",
    "x=layers.UpSampling2D(3)(x)\n",
    "x=layers.Conv2DTranspose(16,3,activation='relu')(x)\n",
    "decoder_output=layers.Conv2DTranspose(1,3,activation='relu')(x)\n",
    "autodecoder = keras.Model(encoder_input,decoder_output,name='autodecoder')\n",
    "autodecoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义好模型后 ，你可以像使用layer一样使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建复杂的图拓扑\n",
    "### 定义有多个输入和输出的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"multimodel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "title (InputLayer)              [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "body (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, None, 64)     640000      title[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, None, 64)     640000      body[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 128)          98816       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 32)           12416       embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tags (InputLayer)               [(None, 12)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 172)          0           lstm_6[0][0]                     \n",
      "                                                                 lstm_7[0][0]                     \n",
      "                                                                 tags[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "priority (Dense)                (None, 1)            173         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "department (Dense)              (None, 4)            692         concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,392,097\n",
      "Trainable params: 1,392,097\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_tags=12\n",
    "num_words=10000\n",
    "num_departments=4\n",
    "title_input=keras.Input(shape=(None,),name='title')\n",
    "body_input=keras.Input(shape=(None,),name='body')\n",
    "tags_input=keras.Input(shape=(num_tags,),name='tags')\n",
    "# embedding\n",
    "title_features=layers.Embedding(num_words,64)(title_input)\n",
    "body_features=layers.Embedding(num_words,64)(body_input)\n",
    "title_features=layers.LSTM(128)(title_features)\n",
    "body_features=layers.LSTM(32)(body_features)\n",
    "x=layers.concatenate([title_features,body_features,tags_input])\n",
    "priority_pred=layers.Dense(1,name='priority')(x)\n",
    "department_pred=layers.Dense(num_departments,name='department')(x)\n",
    "model=keras.Model(inputs=[title_input,body_input,tags_input],outputs=[priority_pred,department_pred],name='multimodel')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model,'multi_input_and_output_model.png',show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "        \"department\": keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "    },\n",
    "    loss_weights=[1.0, 0.2],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "model.fit(\n",
    "    {\"title\": title_data, \"body\": body_data, \"tags\": tags_data},\n",
    "    {\"priority\": priority_targets, \"department\": dept_targets},\n",
    "    epochs=2,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
